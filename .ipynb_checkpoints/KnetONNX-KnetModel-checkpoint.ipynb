{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "push!(LOAD_PATH, \".\");\n",
    "using Knet; using KnetONNX;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model inputs: [\"input\"]\n",
      "model outputs: [\"7\"]\n",
      "(op1) Gemm\n",
      "\tinput1: input\n",
      "\tinput2: linear1.weight\n",
      "\tinput3: linear1.bias\n",
      "\toutput1: 5\n",
      "(op2) Gemm\n",
      "\tinput1: input\n",
      "\tinput2: linear2.weight\n",
      "\tinput3: linear2.bias\n",
      "\toutput1: 6\n",
      "(op3) Add\n",
      "\tinput1: 5\n",
      "\tinput2: 6\n",
      "\toutput1: 7\n"
     ]
    }
   ],
   "source": [
    "g = ONNXtoGraph(\"branch1.onnx\");\n",
    "PrintGraph(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "get_ModelLayers (generic function with 1 method)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "struct ModelLayer\n",
    "    inputs #list of strings\n",
    "    layer # a KnetLayer\n",
    "    outputs #list of strings\n",
    "end\n",
    "\n",
    "function ModelLayer(node, g)\n",
    "    (args, layer, outputs) = node_to_layer(node, g)\n",
    "    ModelLayer(args, layer, outputs)\n",
    "end\n",
    "\n",
    "function get_ModelLayers(g)\n",
    "    ModelLayers = []\n",
    "    for node in g.node; push!(ModelLayers, ModelLayer(node, g)); end\n",
    "    return ModelLayers\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "node_to_layer (generic function with 1 method)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# graph node, graph -> ModelLayer\n",
    "function node_to_layer(node, g)\n",
    "    if node.op_type == \"Gemm\"; return node_to_gemm(node, g); end\n",
    "    if node.op_type == \"Add\"; return node_to_add(node, g); end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "node_to_gemm (generic function with 1 method)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#returns (names of tensors used for forward pass, KnetLayer, output tensor names)\n",
    "function node_to_gemm(node, g)\n",
    "    input1 = node.input[1]\n",
    "    \n",
    "    #the layer is a Knet Layer\n",
    "    layer = KnetONNX.KnetLayers.Linear(input=1,output=1)\n",
    "    \n",
    "    # use g.initializer to modify KnetLayer\n",
    "    w_name = node.input[2]\n",
    "    b_name = node.input[3]\n",
    "    w = g.initializer[w_name]\n",
    "    b = g.initializer[b_name]\n",
    "    layer.bias = b\n",
    "    layer.mult.weight = transpose(w)\n",
    "    \n",
    "    # return input tensor NAMES, it is called args: [input1, ...]\n",
    "    # you can take the inputs from model.tensors using these names\n",
    "    args = [input1]\n",
    "    outs = [node]\n",
    "   \n",
    "    # returns these 3, use these to create ModelLayer\n",
    "    (args, layer, node.output)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModelLayer(AbstractString[\"5\", \"6\"], AddLayer(), AbstractString[\"7\"])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# graph node, graph -> ModelLayer\n",
    "struct AddLayer; end\n",
    "(a::AddLayer)(x,y) = x+y\n",
    "\n",
    "function node_to_add(node, g)\n",
    "    args = node.input\n",
    "    outs = node.output\n",
    "    layer = AddLayer()\n",
    "    return (args, layer, outs)\n",
    "end\n",
    "\n",
    "node3 = g.node[3]\n",
    "ModelLayer(node3, g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorDict (generic function with 1 method)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mutable struct KnetModel\n",
    "    tensors\n",
    "    model_layers\n",
    "    model_inputs\n",
    "    model_outputs\n",
    "end\n",
    "\n",
    "function KnetModel(g::KnetONNX.Types.Graph)\n",
    "    tensors = TensorDict(g)\n",
    "    model_layers = get_ModelLayers(g)\n",
    "    model_inputs = [i.name for i in g.input]\n",
    "    model_outputs = [o.name for o in g.output]\n",
    "    KnetModel(tensors, model_layers, model_inputs, model_outputs)\n",
    "end\n",
    "\n",
    "function TensorDict(g::KnetONNX.Types.Graph)\n",
    "    tensors = Dict()\n",
    "    for node in g.node\n",
    "        for input in node.input; tensors[input] = Nothing; end\n",
    "        for output in node.output; tensors[output] = Nothing; end\n",
    "    end\n",
    "    for (node, value) in g.initializer; tensors[node] = value; end\n",
    "    tensors\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{Any,Any} with 8 entries:\n",
       "  \"linear1.bias\"   => Float32[0.0216016, 0.0483992, -0.0252835, -0.00927702, 0.…\n",
       "  \"linear2.weight\" => Float32[0.0591993 -0.0515833 … 5.5477e-5 -0.089789; -0.03…\n",
       "  \"5\"              => Nothing\n",
       "  \"linear2.bias\"   => Float32[0.0425705, 0.0738719, -0.00153907, 0.064978, 0.06…\n",
       "  \"6\"              => Nothing\n",
       "  \"7\"              => Nothing\n",
       "  \"input\"          => Nothing\n",
       "  \"linear1.weight\" => Float32[-0.0625393 0.00734643 … 0.0502301 -0.0454649; -0.…"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = KnetModel(g)\n",
    "model.tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model, layer -> compute forward pass\n",
    "function forward(km::KnetModel, ml::ModelLayer)\n",
    "    \n",
    "        # GATHER INPUTS\n",
    "    for input in ml.inputs\n",
    "        if km.tensors[input] == Nothing; return \"oops!\"; end\n",
    "    end\n",
    "\n",
    "        # FORWARD PASS\n",
    "        # if only one input is requried, pass the first element\n",
    "        # if more than one input is required, pass all elements\n",
    "        # simply check the length of requried inputs for the model\n",
    "    inputs = (key-> km.tensors[key]).(ml.inputs)\n",
    "    if length(inputs) == 1; out = ml.layer(inputs[1]); \n",
    "        else; out = ml.layer(inputs...); end\n",
    "    \n",
    "        # SAVE OUTPUTS\n",
    "        # check if there are multiple outputs (rnn etc.) before saving them to model.tensors\n",
    "    if length(ml.outputs) == 1; km.tensors[ml.outputs[1]] = out; \n",
    "        else; for output in ml.outputs; km.tensors[output] = out; end; end\n",
    " end\n",
    "\n",
    "function (m::KnetModel)(x)\n",
    "        \n",
    "        # REGISTER X\n",
    "    \n",
    "    #dumb version\n",
    "    # check if we want multiple inputs (x should be a list) or a single input (x is a single array)\n",
    "    #if length(m.model_inputs) == 1; m.tensors[m.model_inputs[1]] = x; \n",
    "    #    else; for (i,model_input) in enumerate(m.model_inputs); m.tensors[model_input] = x[i]; end; end\n",
    "    \n",
    "    m.tensors[m.model_inputs...] = x\n",
    "    \n",
    "    #m.tensors[m.model_inputs...] = 100\n",
    "\n",
    "        # LOOP UNTIL ALL TENSORS ARE CALCULATED\n",
    "    # do until all model.tensors are filled \n",
    "    # iterate over all layers and call forward on that layer\n",
    "    while Nothing in values(m.tensors)\n",
    "        for layer in m.model_layers\n",
    "            forward(m, layer)\n",
    "        end\n",
    "    end\n",
    "    T\n",
    "        # RETURN MODEL OUTPUTS\n",
    "    m.tensors[m.model_outputs...]\n",
    "    #= DUMB VERSION\n",
    "    # could be multiple\n",
    "    if length(m.model_outputs) == 1; return m.tensors[m.model_outputs[1]]; \n",
    "        else; outs = []; for out in m.model_outputs; push!(outs, m.tensors[out]); end; return outs; end\n",
    "    =#\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{Any,Any} with 8 entries:\n",
       "  \"linear1.bias\"   => Float32[0.0216016, 0.0483992, -0.0252835, -0.00927702, 0.…\n",
       "  \"linear2.weight\" => Float32[0.0591993 -0.0515833 … 5.5477e-5 -0.089789; -0.03…\n",
       "  \"5\"              => Nothing\n",
       "  \"linear2.bias\"   => Float32[0.0425705, 0.0738719, -0.00153907, 0.064978, 0.06…\n",
       "  \"6\"              => Nothing\n",
       "  \"7\"              => Nothing\n",
       "  \"input\"          => Nothing\n",
       "  \"linear1.weight\" => Float32[-0.0625393 0.00734643 … 0.0502301 -0.0454649; -0.…"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = KnetModel(g)\n",
    "model.tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10×50 Array{Float64,2}:\n",
       "  0.115668   0.115668   0.115668  …   0.115668   0.115668   0.115668\n",
       "  0.661428   0.661428   0.661428      0.661428   0.661428   0.661428\n",
       "  1.26032    1.26032    1.26032       1.26032    1.26032    1.26032 \n",
       " -0.799757  -0.799757  -0.799757     -0.799757  -0.799757  -0.799757\n",
       " -0.14344   -0.14344   -0.14344      -0.14344   -0.14344   -0.14344 \n",
       "  0.188061   0.188061   0.188061  …   0.188061   0.188061   0.188061\n",
       " -0.815466  -0.815466  -0.815466     -0.815466  -0.815466  -0.815466\n",
       "  1.73175    1.73175    1.73175       1.73175    1.73175    1.73175 \n",
       "  0.508684   0.508684   0.508684      0.508684   0.508684   0.508684\n",
       " -1.20156   -1.20156   -1.20156      -1.20156   -1.20156   -1.20156 "
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_input = ones(100,50);\n",
    "model(dummy_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.2.0",
   "language": "julia",
   "name": "julia-1.2"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
